{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6722f00",
   "metadata": {},
   "source": [
    "# Data loading - check to correctly understand data / label format\n",
    "\n",
    "- load data from conformal boundary example dataset\n",
    "- watch how data changes formats / shapes throughout the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b86795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pytorch3dunet\n",
    "import pytorch3dunet.unet3d as u3  # !\n",
    "from pytorch3dunet import predict\n",
    "from pytorch3dunet import train\n",
    "\n",
    "from pytorch3dunet.unet3d import trainer as trainer\n",
    "from pytorch3dunet.unet3d.config import _load_config_yaml\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf1f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = True  # (False if ben) thinking we could maintain different filepaths here -- or we could copy the whole notebook and maintain two different working notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5a0f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_config.yml',\n",
       " 'test_config.yml~',\n",
       " 'ovules_raw.png',\n",
       " 'ovules_pred.png',\n",
       " 'train_config.yml']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dir = './3DUnet_confocal_boundary'\n",
    "config_filename = 'test_config.yml'\n",
    "os.listdir(config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63109735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': 'PATH_TO_BEST_CHECKPOINT',\n",
       " 'model': {'name': 'UNet3D',\n",
       "  'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'layer_order': 'gcr',\n",
       "  'f_maps': 32,\n",
       "  'num_groups': 8,\n",
       "  'final_sigmoid': True},\n",
       " 'predictor': {'name': 'StandardPredictor'},\n",
       " 'loaders': {'output_dir': '/scratch/groups/jyeatman/samjohns-projects/unet3d/data/test-checkpoints',\n",
       "  'batch_size': 1,\n",
       "  'num_workers': 2,\n",
       "  'test': {'file_paths': ['/scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test'],\n",
       "   'slice_builder': {'name': 'SliceBuilder',\n",
       "    'patch_shape': [80, 170, 170],\n",
       "    'stride_shape': [40, 90, 90]},\n",
       "   'transformer': {'raw': [{'name': 'Standardize'},\n",
       "     {'name': 'ToTensor', 'expand_dims': True}]}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_filepath = f'{config_dir}/{config_filename}'\n",
    "config = _load_config_yaml(config_filepath)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78dadeb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaders = pytorch3dunet.datasets.utils.get_test_loaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f24470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 00:12:38,667 [MainThread] INFO Dataset - Creating test set loaders...\n",
      "2023-05-17 00:12:38,668 [MainThread] WARNING Dataset - Cannot find dataset class in the config. Using default 'StandardHDF5Dataset'.\n",
      "2023-05-17 00:12:38,669 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:40,499 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:40,583 [MainThread] INFO HDF5Dataset - Number of patches: 432\n",
      "2023-05-17 00:12:40,584 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:43,115 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:43,116 [MainThread] INFO HDF5Dataset - Number of patches: 1296\n",
      "2023-05-17 00:12:43,117 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:46,273 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:46,276 [MainThread] INFO HDF5Dataset - Number of patches: 1452\n",
      "2023-05-17 00:12:46,277 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:47,642 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:47,643 [MainThread] INFO HDF5Dataset - Number of patches: 195\n",
      "2023-05-17 00:12:47,644 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:49,351 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:49,352 [MainThread] INFO HDF5Dataset - Number of patches: 810\n",
      "2023-05-17 00:12:49,353 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:51,630 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:51,633 [MainThread] INFO HDF5Dataset - Number of patches: 770\n",
      "2023-05-17 00:12:51,634 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:52,732 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:52,733 [MainThread] INFO HDF5Dataset - Number of patches: 192\n",
      "2023-05-17 00:12:52,734 [MainThread] INFO Dataset - Number of workers for the dataloader: 2\n",
      "2023-05-17 00:12:52,734 [MainThread] INFO Dataset - Batch size for dataloader: 1\n",
      "2023-05-17 00:12:52,735 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1c54eb400>\n",
      "2023-05-17 00:12:52,735 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d850>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d640>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d7c0>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d040>\n",
      "2023-05-17 00:12:52,737 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d250>\n",
      "2023-05-17 00:12:52,737 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d460>\n"
     ]
    }
   ],
   "source": [
    "for l in loaders:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b607f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 00:19:20,062 [MainThread] INFO Dataset - Creating test set loaders...\n",
      "2023-05-17 00:19:20,063 [MainThread] WARNING Dataset - Cannot find dataset class in the config. Using default 'StandardHDF5Dataset'.\n",
      "2023-05-17 00:19:20,064 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:20,689 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:20,691 [MainThread] INFO HDF5Dataset - Number of patches: 432\n",
      "2023-05-17 00:19:20,692 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:22,678 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:22,680 [MainThread] INFO HDF5Dataset - Number of patches: 1296\n",
      "2023-05-17 00:19:22,684 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:25,031 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:25,034 [MainThread] INFO HDF5Dataset - Number of patches: 1452\n",
      "2023-05-17 00:19:25,035 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:25,494 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:25,495 [MainThread] INFO HDF5Dataset - Number of patches: 195\n",
      "2023-05-17 00:19:25,496 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:26,755 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:26,756 [MainThread] INFO HDF5Dataset - Number of patches: 810\n",
      "2023-05-17 00:19:26,757 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:28,164 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:28,165 [MainThread] INFO HDF5Dataset - Number of patches: 770\n",
      "2023-05-17 00:19:28,166 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:28,559 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:28,560 [MainThread] INFO HDF5Dataset - Number of patches: 192\n",
      "2023-05-17 00:19:28,561 [MainThread] INFO Dataset - Number of workers for the dataloader: 2\n",
      "2023-05-17 00:19:28,561 [MainThread] INFO Dataset - Batch size for dataloader: 1\n",
      "2023-05-17 00:19:28,562 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n"
     ]
    }
   ],
   "source": [
    "l = next(iter(loaders))  # if this is new to you, it's actually the *standard* way to use a PyTorch `DataLoader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08bae549",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e76b85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0]  # but why??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a432ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 170, 170])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f94982e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 80, None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40004edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = u3.model.get_model(config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94c1519a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9896480a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m(model, ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "summary(model, ((1, 256, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24b2bba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Unable to open file (file read failed: time = Wed May 17 02:11:26 2023\n, filename = '/scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test', file descriptor = 56, errno = 21, error message = 'Is a directory', buf = 0x7ffe65145420, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_dir \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaders\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_paths\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# why so nested? eh, I guess I understand it...\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/groups/jyeatman/software/anaconda3/envs/pytorch-3dunet/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/home/groups/jyeatman/software/anaconda3/envs/pytorch-3dunet/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Unable to open file (file read failed: time = Wed May 17 02:11:26 2023\n, filename = '/scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test', file descriptor = 56, errno = 21, error message = 'Is a directory', buf = 0x7ffe65145420, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "test_dir = config['loaders']['test']['file_paths'][0]  # why so nested? eh, I guess I understand it...\n",
    "f = h5py.File(test_dir, 'r')\n",
    "\n",
    "# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adc6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-3dunet]",
   "language": "python",
   "name": "conda-env-pytorch-3dunet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

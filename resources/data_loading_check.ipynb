{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6722f00",
   "metadata": {},
   "source": [
    "# Data loading - check to correctly understand data / label format\n",
    "\n",
    "- load data from conformal boundary example dataset\n",
    "- watch how data changes formats / shapes throughout the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b86795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pytorch3dunet\n",
    "import pytorch3dunet.unet3d as u3  # !\n",
    "from pytorch3dunet import predict\n",
    "from pytorch3dunet import train\n",
    "\n",
    "from pytorch3dunet.unet3d import trainer as trainer\n",
    "from pytorch3dunet.unet3d.config import _load_config_yaml\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a53cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = True  # (False if ben) thinking we could maintain different filepaths here -- or we could copy the whole notebook and maintain two different working notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5a0f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_config.yml',\n",
       " 'test_config.yml~',\n",
       " 'ovules_raw.png',\n",
       " 'ovules_pred.png',\n",
       " 'train_config.yml']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dir = './3DUnet_confocal_boundary'\n",
    "config_filename = 'test_config.yml'\n",
    "os.listdir(config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63109735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': 'PATH_TO_BEST_CHECKPOINT',\n",
       " 'model': {'name': 'UNet3D',\n",
       "  'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'layer_order': 'gcr',\n",
       "  'f_maps': 32,\n",
       "  'num_groups': 8,\n",
       "  'final_sigmoid': True},\n",
       " 'predictor': {'name': 'StandardPredictor'},\n",
       " 'loaders': {'output_dir': '/scratch/groups/jyeatman/samjohns-projects/unet3d/data/test-checkpoints',\n",
       "  'batch_size': 1,\n",
       "  'num_workers': 2,\n",
       "  'test': {'file_paths': ['/scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test'],\n",
       "   'slice_builder': {'name': 'SliceBuilder',\n",
       "    'patch_shape': [80, 170, 170],\n",
       "    'stride_shape': [40, 90, 90]},\n",
       "   'transformer': {'raw': [{'name': 'Standardize'},\n",
       "     {'name': 'ToTensor', 'expand_dims': True}]}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_filepath = f'{config_dir}/{config_filename}'\n",
    "config = _load_config_yaml(config_filepath)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78dadeb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaders = pytorch3dunet.datasets.utils.get_test_loaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd96198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 00:12:38,667 [MainThread] INFO Dataset - Creating test set loaders...\n",
      "2023-05-17 00:12:38,668 [MainThread] WARNING Dataset - Cannot find dataset class in the config. Using default 'StandardHDF5Dataset'.\n",
      "2023-05-17 00:12:38,669 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:40,499 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:40,583 [MainThread] INFO HDF5Dataset - Number of patches: 432\n",
      "2023-05-17 00:12:40,584 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:43,115 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:43,116 [MainThread] INFO HDF5Dataset - Number of patches: 1296\n",
      "2023-05-17 00:12:43,117 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:46,273 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:46,276 [MainThread] INFO HDF5Dataset - Number of patches: 1452\n",
      "2023-05-17 00:12:46,277 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:47,642 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:47,643 [MainThread] INFO HDF5Dataset - Number of patches: 195\n",
      "2023-05-17 00:12:47,644 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:49,351 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:49,352 [MainThread] INFO HDF5Dataset - Number of patches: 810\n",
      "2023-05-17 00:12:49,353 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:51,630 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:51,633 [MainThread] INFO HDF5Dataset - Number of patches: 770\n",
      "2023-05-17 00:12:51,634 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "2023-05-17 00:12:52,732 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:12:52,733 [MainThread] INFO HDF5Dataset - Number of patches: 192\n",
      "2023-05-17 00:12:52,734 [MainThread] INFO Dataset - Number of workers for the dataloader: 2\n",
      "2023-05-17 00:12:52,734 [MainThread] INFO Dataset - Batch size for dataloader: 1\n",
      "2023-05-17 00:12:52,735 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1c54eb400>\n",
      "2023-05-17 00:12:52,735 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d850>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d640>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d7c0>\n",
      "2023-05-17 00:12:52,736 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d040>\n",
      "2023-05-17 00:12:52,737 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d250>\n",
      "2023-05-17 00:12:52,737 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1da47d460>\n"
     ]
    }
   ],
   "source": [
    "for l in loaders:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8de7ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 00:19:20,062 [MainThread] INFO Dataset - Creating test set loaders...\n",
      "2023-05-17 00:19:20,063 [MainThread] WARNING Dataset - Cannot find dataset class in the config. Using default 'StandardHDF5Dataset'.\n",
      "2023-05-17 00:19:20,064 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:20,689 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:20,691 [MainThread] INFO HDF5Dataset - Number of patches: 432\n",
      "2023-05-17 00:19:20,692 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_435_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:22,678 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:22,680 [MainThread] INFO HDF5Dataset - Number of patches: 1296\n",
      "2023-05-17 00:19:22,684 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_441_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:25,031 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:25,034 [MainThread] INFO HDF5Dataset - Number of patches: 1452\n",
      "2023-05-17 00:19:25,035 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_593_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:25,494 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:25,495 [MainThread] INFO HDF5Dataset - Number of patches: 195\n",
      "2023-05-17 00:19:25,496 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_522_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:26,755 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:26,756 [MainThread] INFO HDF5Dataset - Number of patches: 810\n",
      "2023-05-17 00:19:26,757 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_294_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:28,164 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:28,165 [MainThread] INFO HDF5Dataset - Number of patches: 770\n",
      "2023-05-17 00:19:28,166 [MainThread] INFO HDF5Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_590_final_crop_ds2.h5...\n",
      "2023-05-17 00:19:28,559 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [80, 170, 170], 'stride_shape': [40, 90, 90]}\n",
      "2023-05-17 00:19:28,560 [MainThread] INFO HDF5Dataset - Number of patches: 192\n",
      "2023-05-17 00:19:28,561 [MainThread] INFO Dataset - Number of workers for the dataloader: 2\n",
      "2023-05-17 00:19:28,561 [MainThread] INFO Dataset - Batch size for dataloader: 1\n",
      "2023-05-17 00:19:28,562 [MainThread] INFO Dataset - Loading test set from: /scratch/groups/jyeatman/samjohns-projects/unet3d/data/osfstorage-archive-test/N_511_final_crop_ds2.h5...\n"
     ]
    }
   ],
   "source": [
    "l = next(iter(loaders))  # if this is new to you, it's actually the *standard* way to use a PyTorch `DataLoader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06ec63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee140b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0]  # but why??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47eb6ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 170, 170])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ab606d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 80, None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88384775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40004edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = u3.model.get_model(config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94c1519a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9896480a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m(model, ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "summary(model, ((1, 256, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2bba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-3dunet]",
   "language": "python",
   "name": "conda-env-pytorch-3dunet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
